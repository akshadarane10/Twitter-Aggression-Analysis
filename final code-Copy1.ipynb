{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a461299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n",
      "[nltk_data] Error loading words: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    }
   ],
   "source": [
    "## import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202bcdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk \n",
    "import numpy as np\n",
    "import string\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import re\n",
    "import string\n",
    "from fuzzywuzzy import fuzz  \n",
    "import difflib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ff40390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well said sonu..you have courage to stand agai...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most of Private Banks ATM's Like HDFC, ICICI e...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now question is, Pakistan will adhere to this?</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>??we r against cow slaughter,so of course it w...</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet label\n",
       "0  Well said sonu..you have courage to stand agai...   OAG\n",
       "1  Most of Private Banks ATM's Like HDFC, ICICI e...   NAG\n",
       "2     Now question is, Pakistan will adhere to this?   OAG\n",
       "3  Pakistan is comprised of fake muslims who does...   OAG\n",
       "4  ??we r against cow slaughter,so of course it w...   NAG"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432f9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799add6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64370e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "VERB_CODES = {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fea337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## new\n",
    "def preprocess_sentences(text):\n",
    "    text = text.lower()\n",
    "    text=text.strip()  #get rid of leading/trailing whitespace \n",
    "      \n",
    "    temp_sent =[]\n",
    "    words = nltk.word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    for i, word in enumerate(words):\n",
    "        if tags[i][1] in VERB_CODES:\n",
    "            lemmatized = lemmatizer.lemmatize(word, 'v')\n",
    "        else:\n",
    "            lemmatized = lemmatizer.lemmatize(word)\n",
    "        if lemmatized not in stop_words and lemmatized.isalpha() and len(lemmatized)>2:\n",
    "            temp_sent.append(lemmatized)\n",
    "\n",
    "    finalsent = ' '.join(temp_sent)\n",
    "    \n",
    "    return finalsent\n",
    "\n",
    "\n",
    "df[\"Tweet_clean\"]= df[\"tweet\"].apply(preprocess_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee35d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>Tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well said sonu..you have courage to stand agai...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>well say sonu courage stand dadagiri muslim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Most of Private Banks ATM's Like HDFC, ICICI e...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>private bank atm like hdfc icici etc cash publ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now question is, Pakistan will adhere to this?</td>\n",
       "      <td>OAG</td>\n",
       "      <td>question pakistan adhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan is comprised of fake muslims who does...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>pakistan comprise fake muslim know meaning uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>??we r against cow slaughter,so of course it w...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>cow slaughter course stop leather manufacturin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11994</th>\n",
       "      <td>They belong to you flight dirty terrorist coun...</td>\n",
       "      <td>OAG</td>\n",
       "      <td>belong flight dirty terrorist country india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11995</th>\n",
       "      <td>Really motivating programme, congratulations t...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>really motivate programme congratulation cnbc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11996</th>\n",
       "      <td>fabricated news</td>\n",
       "      <td>OAG</td>\n",
       "      <td>fabricate news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>What's wrong with you secular idiots</td>\n",
       "      <td>OAG</td>\n",
       "      <td>wrong secular idiot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>Looks like inevitable after all political hard...</td>\n",
       "      <td>NAG</td>\n",
       "      <td>look like inevitable political hard ball dialo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet label  \\\n",
       "0      Well said sonu..you have courage to stand agai...   OAG   \n",
       "1      Most of Private Banks ATM's Like HDFC, ICICI e...   NAG   \n",
       "2         Now question is, Pakistan will adhere to this?   OAG   \n",
       "3      Pakistan is comprised of fake muslims who does...   OAG   \n",
       "4      ??we r against cow slaughter,so of course it w...   NAG   \n",
       "...                                                  ...   ...   \n",
       "11994  They belong to you flight dirty terrorist coun...   OAG   \n",
       "11995  Really motivating programme, congratulations t...   NAG   \n",
       "11996                                    fabricated news   OAG   \n",
       "11997               What's wrong with you secular idiots   OAG   \n",
       "11998  Looks like inevitable after all political hard...   NAG   \n",
       "\n",
       "                                             Tweet_clean  \n",
       "0            well say sonu courage stand dadagiri muslim  \n",
       "1      private bank atm like hdfc icici etc cash publ...  \n",
       "2                               question pakistan adhere  \n",
       "3      pakistan comprise fake muslim know meaning uni...  \n",
       "4      cow slaughter course stop leather manufacturin...  \n",
       "...                                                  ...  \n",
       "11994        belong flight dirty terrorist country india  \n",
       "11995  really motivate programme congratulation cnbc ...  \n",
       "11996                                     fabricate news  \n",
       "11997                                wrong secular idiot  \n",
       "11998  look like inevitable political hard ball dialo...  \n",
       "\n",
       "[11999 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fa58261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_clean'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6162f346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              well say sonu courage stand dadagiri muslim\n",
       "1        private bank atm like hdfc icici etc cash publ...\n",
       "2                                 question pakistan adhere\n",
       "3        pakistan comprise fake muslim know meaning uni...\n",
       "4        cow slaughter course stop leather manufacturin...\n",
       "                               ...                        \n",
       "11994          belong flight dirty terrorist country india\n",
       "11995    really motivate programme congratulation cnbc ...\n",
       "11996                                       fabricate news\n",
       "11997                                  wrong secular idiot\n",
       "11998    look like inevitable political hard ball dialo...\n",
       "Name: Tweet_clean, Length: 11999, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41f995eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import randint\n",
    "import seaborn as sns # used for plot interactive graph.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba614bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each of the 11999 tweets is represented by 5215 features (TF-IDF score of unigrams and bigrams)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, ngram_range=(1, 2),stop_words='english')\n",
    "# We transform each complaint into a vector\n",
    "features = tfidf.fit_transform(df.Tweet_clean).toarray()\n",
    "labels = df.label\n",
    "print(\"Each of the %d tweets is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "296d153d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5215,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[5217].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b537c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        OAG\n",
       "1        NAG\n",
       "2        OAG\n",
       "3        OAG\n",
       "4        NAG\n",
       "        ... \n",
       "11994    OAG\n",
       "11995    NAG\n",
       "11996    OAG\n",
       "11997    OAG\n",
       "11998    NAG\n",
       "Name: label, Length: 11999, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "097f7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f537ca0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier train accuracy: 0.4286\n",
      "RandomForestClassifier test accuracy: 0.4261\n",
      "LinearSVC train accuracy: 0.8303\n",
      "LinearSVC test accuracy: 0.5506\n",
      "MultinomialNB train accuracy: 0.7062\n",
      "MultinomialNB test accuracy: 0.5783\n",
      "LogisticRegression train accuracy: 0.7513\n",
      "LogisticRegression test accuracy: 0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshada Rane\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df['Tweet_clean'] # Collection of documents\n",
    "y = df['label'] # Target or the labels we want to predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.15, random_state = 0)\n",
    "\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the training labels and calculate the accuracy\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Predict the test labels and calculate the accuracy\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Print the train and test accuracy for the model\n",
    "    print(f\"{model_name} train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"{model_name} test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed092b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshada Rane\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier train accuracy: 0.4286 | F1: 0.2666 | Precision: 0.5822 | Recall: 0.4286\n",
      "RandomForestClassifier test accuracy: 0.4261 | F1: 0.2621 | Precision: 0.3265 | Recall: 0.4261\n",
      "LinearSVC train accuracy: 0.8303 | F1: 0.8295 | Precision: 0.8302 | Recall: 0.8303\n",
      "LinearSVC test accuracy: 0.5506 | F1: 0.5475 | Precision: 0.5459 | Recall: 0.5506\n",
      "MultinomialNB train accuracy: 0.7062 | F1: 0.6977 | Precision: 0.7192 | Recall: 0.7062\n",
      "MultinomialNB test accuracy: 0.5783 | F1: 0.5668 | Precision: 0.5826 | Recall: 0.5783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshada Rane\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy: 0.7513 | F1: 0.7477 | Precision: 0.7536 | Recall: 0.7513\n",
      "LogisticRegression test accuracy: 0.5867 | F1: 0.5786 | Precision: 0.5797 | Recall: 0.5867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# ... (your previous code)\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the training labels and calculate the accuracy, F1 score, precision, and recall\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average = 'weighted')\n",
    "    train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "    train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "    \n",
    "    # Predict the test labels and calculate the accuracy, F1 score, precision, and recall\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "    \n",
    "    # Print the evaluation metrics for the model\n",
    "    print(f\"{model_name} train accuracy: {train_acc:.4f} | F1: {train_f1:.4f} | Precision: {train_precision:.4f} | Recall: {train_recall:.4f}\")\n",
    "    print(f\"{model_name} test accuracy: {test_acc:.4f} | F1: {test_f1:.4f} | Precision: {test_precision:.4f} | Recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8bcfc423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshada Rane\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier train accuracy: 0.4286 | F1: [0.03893333 0.59875898 0.00347072] | Precision: [0.5       0.4273062 1.       ] | Recall: [0.02025527 1.         0.00173837]\n",
      "RandomForestClassifier test accuracy: 0.4261 | F1: [0.03030303 0.59771023 0.        ] | Precision: [0.41666667 0.42623874 0.        ] | Recall: [0.01572327 1.         0.        ]\n",
      "LinearSVC train accuracy: 0.8303 | F1: [0.80089862 0.8638773  0.81016103] | Precision: [0.81068789 0.8375246  0.84724858] | Recall: [0.79134295 0.89194224 0.77618427]\n",
      "LinearSVC test accuracy: 0.5506 | F1: [0.47665848 0.64724509 0.4725    ] | Precision: [0.4974359  0.6216545  0.48091603] | Recall: [0.45754717 0.67503303 0.46437346]\n",
      "MultinomialNB train accuracy: 0.7062 | F1: [0.67931886 0.78128068 0.57037875] | Precision: [0.63903155 0.73486559 0.8156831 ] | Recall: [0.72502775 0.83395435 0.438505  ]\n",
      "MultinomialNB test accuracy: 0.5783 | F1: [0.53558327 0.67773678 0.4091653 ] | Precision: [0.50206327 0.63406214 0.6127451 ] | Recall: [0.57389937 0.72787318 0.30712531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshada Rane\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression train accuracy: 0.7513 | F1: [0.71995605 0.80872998 0.67716929] | Precision: [0.71280936 0.76430348 0.79740872] | Recall: [0.7272475  0.85863996 0.58843981]\n",
      "LogisticRegression test accuracy: 0.5867 | F1: [0.52118305 0.69015796 0.46088193] | Precision: [0.5300813  0.63892013 0.5472973 ] | Recall: [0.51257862 0.75033025 0.3980344 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# ... (your previous code)\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict the training labels and calculate the accuracy, F1 score, precision, and recall\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=None)  # Corrected 'none' to 'None'\n",
    "    train_precision = precision_score(y_train, y_train_pred, average=None)\n",
    "    train_recall = recall_score(y_train, y_train_pred, average=None)\n",
    "    \n",
    "    # Predict the test labels and calculate the accuracy, F1 score, precision, and recall\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=None)\n",
    "    test_precision = precision_score(y_test, y_test_pred, average=None)\n",
    "    test_recall = recall_score(y_test, y_test_pred, average=None)\n",
    "    \n",
    "    # Print the evaluation metrics for the model\n",
    "    print(f\"{model_name} train accuracy: {train_acc:.4f} | F1: {train_f1} | Precision: {train_precision} | Recall: {train_recall}\")\n",
    "    print(f\"{model_name} test accuracy: {test_acc:.4f} | F1: {test_f1} | Precision: {test_precision} | Recall: {test_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a184b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes train accuracy: 0.7113\n",
      "Multinomial Naive Bayes test accuracy: 0.5729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['Tweet_clean'] # Collection of documents\n",
    "y = df['label'] # Target or the labels we want to predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=0)\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = nb.predict(X_train)\n",
    "y_test_pred = nb.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_train_pred)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Multinomial Naive Bayes train accuracy: {train_acc:.4f}\")\n",
    "print(f\"Multinomial Naive Bayes test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1e562",
   "metadata": {},
   "source": [
    "# The below is the best model working with almost similar training and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "649bf368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dbfcc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df['Tweet_clean'] # Collection of documents\n",
    "y = df['label'] # Target or the labels we want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe404c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Vectorize the text data using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vec = vectorizer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a135da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the data by oversampling the minority class\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_vec, y)\n",
    "\n",
    "# Perform feature selection using chi-squared test\n",
    "selector = SelectKBest(chi2, k=1000)\n",
    "X_resampled_selected = selector.fit_transform(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13939c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled_selected, y_resampled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1046e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection using chi-squared test\n",
    "selector = SelectKBest(chi2, k=1000)\n",
    "X_resampled_selected = selector.fit_transform(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "474f5a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid to search over\n",
    "param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0],\n",
    "              'fit_prior': [True, False]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac86de5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 0.01, 'fit_prior': False}\n",
      "Best cross-validation score: 0.6218622917700742\n"
     ]
    }
   ],
   "source": [
    "# Use cross-validation to evaluate the model's performance on multiple folds of the data and tune the hyperparameters\n",
    "nb = MultinomialNB()\n",
    "grid_search = GridSearchCV(nb, param_grid, cv=10)\n",
    "grid_search.fit(X_resampled_selected, y_resampled)\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f76b1c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.01, fit_prior=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.01, fit_prior=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.01, fit_prior=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train a final model with the best hyperparameters found by the grid search\n",
    "nb = MultinomialNB(alpha=grid_search.best_params_['alpha'], fit_prior=grid_search.best_params_['fit_prior'])\n",
    "nb.fit(X_resampled_selected, y_resampled)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacae593",
   "metadata": {},
   "source": [
    "# Testing & Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f7828c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation train accuracy: 0.6218622917700742\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Predict the labels for the training and test sets using cross-validation\n",
    "scores_train = cross_val_score(nb, X_resampled_selected, y_resampled, cv=10)\n",
    "print(\"Cross-validation train accuracy:\", scores_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3777549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes test accuracy: 0.6226\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the classifier on the test set\n",
    "y_test_pred = nb.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Multinomial Naive Bayes test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3632faf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[643 135 198]\n",
      " [355 571 141]\n",
      " [254  61 673]]\n",
      "Precision: 0.81\n",
      "Recall: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_test_pred = nb.predict(X_test)\n",
    "\n",
    "# Create a confusion matrix for the test set\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Calculate precision and recall from the confusion matrix\n",
    "precision = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[0,1])\n",
    "recall = conf_matrix[1,1] / (conf_matrix[1,1] + conf_matrix[1,0])\n",
    "\n",
    "# Print the confusion matrix, precision, and recall\n",
    "print(\"Confusion matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Precision:\", round(precision,2))\n",
    "print(\"Recall:\", round(recall,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3489221",
   "metadata": {},
   "source": [
    "# Prediction for Adhani Hidenburg Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "435f4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file with the new data\n",
    "new_data = pd.read_excel(\"Adhani_clean.xlsx\")\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "new_data['Tweet'] = new_data['Tweet'].fillna('')\n",
    "\n",
    "\n",
    "# Preprocess the new data\n",
    "#new_data['Tweet_clean'] = new_data['Tweet'].apply(clean_text)\n",
    "X_new = vectorizer.transform(new_data['Tweet'])\n",
    "X_new_selected = selector.transform(X_new)\n",
    "\n",
    "# Predict the labels for the new data\n",
    "y_new_pred = nb.predict(X_new_selected)\n",
    "new_data['Predicted Label'] = y_new_pred\n",
    "\n",
    "# Save the predictions to a new Excel file\n",
    "new_data.to_excel(\"Adhani_clean_pred.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cf43d7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>profile</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followerCount</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-12 13:27:11+00:00</td>\n",
       "      <td>linu_nair</td>\n",
       "      <td>ushanirmala hidenburg adani pyar mein baki bho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-12 13:16:43+00:00</td>\n",
       "      <td>linu_nair</td>\n",
       "      <td>wonder hidenburg cover may occupied adani</td>\n",
       "      <td>NaN</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-12 12:55:29+00:00</td>\n",
       "      <td>StockMarketTyms</td>\n",
       "      <td>hidenburg try best shake indianmarkets many ve...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proud year experience stock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-03-12 12:24:01+00:00</td>\n",
       "      <td>ShivayRudra</td>\n",
       "      <td>hidenburg busy make fake report adani country ...</td>\n",
       "      <td>new delhi india</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-03-12 10:02:53+00:00</td>\n",
       "      <td>viprayami1</td>\n",
       "      <td>narendramodi pmoindia crash shut biggest bank ...</td>\n",
       "      <td>canada</td>\n",
       "      <td>buy kid meritocratic dev dharm jaati desh easi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                       Date             User  \\\n",
       "0             0           0  2023-03-12 13:27:11+00:00        linu_nair   \n",
       "1             1           1  2023-03-12 13:16:43+00:00        linu_nair   \n",
       "2             2           2  2023-03-12 12:55:29+00:00  StockMarketTyms   \n",
       "3             3           3  2023-03-12 12:24:01+00:00      ShivayRudra   \n",
       "4             5           5  2023-03-12 10:02:53+00:00       viprayami1   \n",
       "\n",
       "                                               Tweet         Location  \\\n",
       "0  ushanirmala hidenburg adani pyar mein baki bho...              NaN   \n",
       "1          wonder hidenburg cover may occupied adani              NaN   \n",
       "2  hidenburg try best shake indianmarkets many ve...              NaN   \n",
       "3  hidenburg busy make fake report adani country ...  new delhi india   \n",
       "4  narendramodi pmoindia crash shut biggest bank ...           canada   \n",
       "\n",
       "                                             profile  likes  retweets  \\\n",
       "0                                             indian      0         0   \n",
       "1                                             indian      0         0   \n",
       "2                        proud year experience stock      0         0   \n",
       "3                                                NaN      0         0   \n",
       "4  buy kid meritocratic dev dharm jaati desh easi...      0         0   \n",
       "\n",
       "   followerCount Predicted Label  \n",
       "0             17             CAG  \n",
       "1             17             CAG  \n",
       "2             21             NAG  \n",
       "3             62             NAG  \n",
       "4             91             NAG  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12e35cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAG    15681\n",
       "NAG    10631\n",
       "OAG     3352\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bf36697",
   "metadata": {},
   "outputs": [],
   "source": [
    "###End: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8fc529",
   "metadata": {},
   "source": [
    "# Predictions of Shinde Govt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d82a4cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file with the new data\n",
    "new_data = pd.read_excel(\"Shinde_clean.xlsx\")\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "new_data['Tweet'] = new_data['Tweet'].fillna('')\n",
    "\n",
    "\n",
    "# Preprocess the new data\n",
    "#new_data['Tweet_clean'] = new_data['Tweet'].apply(clean_text)\n",
    "X_new = vectorizer.transform(new_data['Tweet'])\n",
    "X_new_selected = selector.transform(X_new)\n",
    "\n",
    "# Predict the labels for the new data\n",
    "y_new_pred = nb.predict(X_new_selected)\n",
    "new_data['Predicted Label'] = y_new_pred\n",
    "\n",
    "# Save the predictions to a new Excel file\n",
    "new_data.to_excel(\"Shinde_clean_pred.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "410f31c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAG    6598\n",
       "NAG    2532\n",
       "OAG    1341\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe40a67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>profile</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followerCount</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-26 20:31:33+00:00</td>\n",
       "      <td>MayurShinde4</td>\n",
       "      <td>anyone attack govt report btw demand jpc reque...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-03-26 18:24:51+00:00</td>\n",
       "      <td>VinayShindeBlr</td>\n",
       "      <td>enemywithin putin yanukovych jinping get modi ...</td>\n",
       "      <td>bharat union state</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>966</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-03-26 15:09:07+00:00</td>\n",
       "      <td>pareshshinde38</td>\n",
       "      <td>blblvishwa ani stop financial base reservation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2023-03-26 14:06:55+00:00</td>\n",
       "      <td>ShashankNair2</td>\n",
       "      <td>maharashtra shinde meet mns chief rajthackeray...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>journalist news</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2023-03-26 12:22:54+00:00</td>\n",
       "      <td>SRH_IS_LUB</td>\n",
       "      <td>shindeshahiinmaharashtra shinde bulldozer man ...</td>\n",
       "      <td>milkyway galaxy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>197</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date            User  \\\n",
       "0           0  2023-03-26 20:31:33+00:00    MayurShinde4   \n",
       "1           1  2023-03-26 18:24:51+00:00  VinayShindeBlr   \n",
       "2           2  2023-03-26 15:09:07+00:00  pareshshinde38   \n",
       "3           3  2023-03-26 14:06:55+00:00   ShashankNair2   \n",
       "4           4  2023-03-26 12:22:54+00:00      SRH_IS_LUB   \n",
       "\n",
       "                                               Tweet            Location  \\\n",
       "0  anyone attack govt report btw demand jpc reque...                 NaN   \n",
       "1  enemywithin putin yanukovych jinping get modi ...  bharat union state   \n",
       "2  blblvishwa ani stop financial base reservation...                 NaN   \n",
       "3  maharashtra shinde meet mns chief rajthackeray...                 NaN   \n",
       "4  shindeshahiinmaharashtra shinde bulldozer man ...     milkyway galaxy   \n",
       "\n",
       "           profile  likes  retweets  followerCount Predicted Label  \n",
       "0              NaN      1         0              8             CAG  \n",
       "1              NaN      0         0            966             OAG  \n",
       "2              NaN      0         0              4             CAG  \n",
       "3  journalist news      2         2             73             CAG  \n",
       "4              NaN      1        21            197             CAG  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ad3d7",
   "metadata": {},
   "source": [
    "# Prediction for Cricket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "209afc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file with the new data\n",
    "new_data = pd.read_excel(\"Cricket_clean.xlsx\")\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "new_data['Tweet'] = new_data['Tweet'].fillna('')\n",
    "\n",
    "\n",
    "# Preprocess the new data\n",
    "#new_data['Tweet_clean'] = new_data['Tweet'].apply(clean_text)\n",
    "X_new = vectorizer.transform(new_data['Tweet'])\n",
    "X_new_selected = selector.transform(X_new)\n",
    "\n",
    "# Predict the labels for the new data\n",
    "y_new_pred = nb.predict(X_new_selected)\n",
    "new_data['Predicted Label'] = y_new_pred\n",
    "\n",
    "# Save the predictions to a new Excel file\n",
    "new_data.to_excel(\"Cricket_clean_pred.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2155bb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Location</th>\n",
       "      <th>profile</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>followerCount</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-12-29 13:33:02+00:00</td>\n",
       "      <td>mkaif_786</td>\n",
       "      <td>jbsy bowl lineup ayi world cup pakistan final ...</td>\n",
       "      <td>cricket</td>\n",
       "      <td>pct pakistan cricket important student</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2416.0</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-12-28 13:04:06+00:00</td>\n",
       "      <td>Ammi42737578</td>\n",
       "      <td>pakistan newzland test safique babar wasim eng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abðÿ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-12-27 03:25:59+00:00</td>\n",
       "      <td>rathoure_b</td>\n",
       "      <td>viratgodfather tab opposition tab india team j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>anime love</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-12-25 14:41:22+00:00</td>\n",
       "      <td>SwaradevB</td>\n",
       "      <td>icc would like pakistan semifinal world cup fo...</td>\n",
       "      <td>rayagada india</td>\n",
       "      <td>nature lover twitter use person</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2022-12-24 09:20:43+00:00</td>\n",
       "      <td>Drjunaid79</td>\n",
       "      <td>vibhubhola still pakistan play world cup semif...</td>\n",
       "      <td>peshawar pakistan</td>\n",
       "      <td>study save life vet doctor uvasian uvas</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>OAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       Date          User  \\\n",
       "0           0  2022-12-29 13:33:02+00:00     mkaif_786   \n",
       "1           1  2022-12-28 13:04:06+00:00  Ammi42737578   \n",
       "2           2  2022-12-27 03:25:59+00:00    rathoure_b   \n",
       "3           3  2022-12-25 14:41:22+00:00     SwaradevB   \n",
       "4           5  2022-12-24 09:20:43+00:00    Drjunaid79   \n",
       "\n",
       "                                               Tweet           Location  \\\n",
       "0  jbsy bowl lineup ayi world cup pakistan final ...            cricket   \n",
       "1  pakistan newzland test safique babar wasim eng...                NaN   \n",
       "2  viratgodfather tab opposition tab india team j...                NaN   \n",
       "3  icc would like pakistan semifinal world cup fo...     rayagada india   \n",
       "4  vibhubhola still pakistan play world cup semif...  peshawar pakistan   \n",
       "\n",
       "                                   profile  likes  retweets  followerCount  \\\n",
       "0   pct pakistan cricket important student    3.0       0.0         2416.0   \n",
       "1                                     abðÿ    0.0       0.0            0.0   \n",
       "2                               anime love    0.0       0.0           12.0   \n",
       "3          nature lover twitter use person    0.0       0.0           23.0   \n",
       "4  study save life vet doctor uvasian uvas    1.0       0.0          130.0   \n",
       "\n",
       "  Predicted Label  \n",
       "0             NAG  \n",
       "1             CAG  \n",
       "2             NAG  \n",
       "3             NAG  \n",
       "4             OAG  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "483a7dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAG    1744\n",
       "OAG    1441\n",
       "CAG     721\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605de4f",
   "metadata": {},
   "source": [
    "# Shraddha Walker Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f29c5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file with the new data\n",
    "new_data = pd.read_excel(\"datasetSW.xlsx\")\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "new_data['Tweet'] = new_data['Tweet'].fillna('')\n",
    "\n",
    "\n",
    "# Preprocess the new data\n",
    "#new_data['Tweet_clean'] = new_data['Tweet'].apply(clean_text)\n",
    "X_new = vectorizer.transform(new_data['Tweet'])\n",
    "X_new_selected = selector.transform(X_new)\n",
    "\n",
    "# Predict the labels for the new data\n",
    "y_new_pred = nb.predict(X_new_selected)\n",
    "new_data['Predicted Label'] = y_new_pred\n",
    "\n",
    "# Save the predictions to a new Excel file\n",
    "new_data.to_excel(\"datasetSW_Prediction.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bb004f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CAG    10581\n",
       "OAG     5263\n",
       "NAG     2463\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f3102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
